1. HashMap 和 Hashtable 区别

    * 继承的父类不同：HashMap继承自AbstractMap类;HashTable继承自Dictionary类
    * 线程安全性：hashmap 是线程不安全的;hashtable 是线程安全的
    * 序列化: hashtable 支持序列化，实现了Cloneable接口，能被克隆
    * 包含的contains方法不同 HashTable 有contains方法，HashMap没有
    * Hashmap 允许null值，hashtable不能为空
    * 计算hash值方式不同：hashmap使用自己的hash方法计算，hashtable使用hashCode()计算

2. Java 垃圾回收机制和生命周期 

    垃圾回收可以有效的防止内存泄露，有效的使用空闲的内存
    java 的对象实例存放在 堆中，垃圾回收主要运用在堆中。当java进程中的堆内存快慢的时候，启动垃圾回收，清理没有用处的对象内存。

    生命周期：新生代，老年代，永久代。垃圾回收主要清理新生代和老年代。

    标记算法：
    引用计数法：一个对象如果被引用，计数器+1，循环引用会失效
    可达性分析：从根寻找到底，如果可达，打标记。从虚拟机栈，本地方法栈，常量池的引用为根。

    垃圾回收算法：
    标记-清除：先标记，后直接清除，产生大量内存碎片
    标记-整理：先标记，后直接移动到一起，移动耗时过大
    复制：有两块区域，每次只使用一个空间。先标记，后将不需要清除的放到另一个空间，清除之前的空间。只使用一半内存，浪费

    垃圾收集器：
    新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge
    老年代收集器使用的收集器：Serial Old、Parallel Old、CMS
    都清理的收集器：G1

    serial：复制算法，停顿，串行
    serial Old：标记-整理，停顿，串行
    parnew：复制算法，停顿，并行
    parallel scavenge：复制算法，高吞吐量，并行
    parallel old：复制算法，高吞吐量，并行
    CMS：标记清理算法，小停顿，低延时，CPU高，并行
    G1：分块的标记整理

    GC执行机制：
    full gc：老年代或永久代被写满/system.gc()
    scavenge gc：申请新生代中的eden区失败时触发。

3. 怎么解决 Kafka 数据丢失的问题 

    消费端丢失数据：自动提交offset，但是挂掉了。解决方案：手都提交offset
    Kafka 弄丢数据：kafka某个broker宕机，然后重新选举partition的leader。解决方案：acks=all，retries=max
    生产者弄丢数据：解决方案：acks=all

4. 请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?

    1）NameNode：主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。
    2）SecondaryNameNode：提供周期检查点和清理任务
    3）DataNode：实际存储数据的节点，提供读写功能。每个存储数据的节点运行一个datanode守护进程。
    4）ResourceManager：负责调度工作。每个DataNode有一个NodeManager，它们执行实际工作。
    5）NodeManager：执行任务。
    6）DFSZKFailoverController：监控NN的状态，并及时的把状态信息写入ZK。目前选择策略还比较简单（先到先得，轮换）。
    7）JournalNode：高可用情况下存放namenode的editlog文件。

5. 文件大小设置，增大有什么影响？

    HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。 因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率。

6. HDFS写数据过程

    1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。
    2）NameNode返回是否可以上传。
    3）客户端请求第一个 block上传到哪几个datanode服务器上。
    4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。
    5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。
    6）dn1、dn2、dn3逐级应答客户端。
    7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3； dn1每传一个packet会放入一个应答队列等待应答。
    8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。

7. HDFS读数据过程

    1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。
    2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。
    3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。
    4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。

8. secondary namenode工作机制

    1）第一阶段：NameNode启动
      （1）第一次启动NameNode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
      （2）客户端对元数据进行增删改的请求。
      （3）NameNode记录操作日志，更新滚动日志。
      （4）NameNode在内存中对数据进行增删改查。
    2）第二阶段：Secondary NameNode工作
      （1）Secondary NameNode询问NameNode是否需要checkpoint。直接带回NameNode是否检查结果。
      （2）Secondary NameNode请求执行checkpoint。
      （3）NameNode滚动正在写的edits日志。
      （4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。
      （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。
      （6）生成新的镜像文件fsimage.chkpoint。
      （7）拷贝fsimage.chkpoint到NameNode。
      （8）NameNode将fsimage.chkpoint重新命名成fsimage。

9. NameNode与SecondaryNameNode 的区别与联系

    1）区别
      （1）NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。
      （2）SecondaryNameNode主要用于定期合并命名空间镜像和命名空间镜像的编辑日志。
    2）联系：
      （1）SecondaryNameNode中保存了一份和namenode一致的镜像文件（fsimage）和编辑日志（edits）。
      （2）在主namenode发生故障时（假设没有及时备份数据），可以从SecondaryNameNode恢复数据。

10. HDFS组成架构

    架构主要由四个部分组成，分别为HDFS Client、NameNode、DataNode和Secondary NameNode。下面我们分别介绍这四个组成部分。
    1）Client：就是客户端。
      （1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行存储；
      （2）与NameNode交互，获取文件的位置信息；
      （3）与DataNode交互，读取或者写入数据；
      （4）Client提供一些命令来管理HDFS，比如启动或者关闭HDFS；
      （5）Client可以通过一些命令来访问HDFS；
    2）NameNode：就是Master，它是一个主管、管理者。
      （1）管理HDFS的名称空间；
      （2）管理数据块（Block）映射信息；
      （3）配置副本策略；
      （4）处理客户端读写请求。
    3）DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。
      （1）存储实际的数据块；
      （2）执行数据块的读/写操作。
    4）Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。
      （1）辅助NameNode，分担其工作量；
      （2）定期合并Fsimage和Edits，并推送给NameNode；
      （3）在紧急情况下，可辅助恢复NameNode。

11. HAnamenode 是如何工作的

    ZKFailoverController主要职责
      1）健康监测：周期性的向它监控的NN发送健康探测命令，从而来确定某个NameNode是否处于健康状态，如果机器宕机，心跳失败，那么zkfc就会标记它处于一个不健康的状态。
      2）会话管理：如果NN是健康的，zkfc就会在zookeeper中保持一个打开的会话，如果NameNode同时还是Active状态的，那么zkfc还会在Zookeeper中占有一个类型为短暂类型的znode，当这个NN挂掉时，这个znode将会被删除，然后备用的NN，将会得到这把锁，升级为主NN，同时标记状态为Active。
      3）当宕机的NN新启动时，它会再次注册zookeper，发现已经有znode锁了，便会自动变为Standby状态，如此往复循环，保证高可靠，需要注意，目前仅仅支持最多配置2个NN。
      4）master选举：如上所述，通过在zookeeper中维持一个短暂类型的znode，来实现抢占式的锁机制，从而判断那个NameNode为Active状态

12. HDFS的数据压缩算法

    Hadoop中常用的压缩算法有bzip2、gzip、lzo、snappy，其中lzo、snappy需要操作系统安装native库才可以支持。

13. Hadoop的调度器总结

    默认的调度器FIFO：先按照作业的优先级高低，再按照到达时间的先后选择被执行的作业
    容量调度器Capacity Scheduler：多队列，多用户，会提前配置每个队列容量，为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定
    公平调度器Fair Scheduler：持多队列多用户，每个队列中的资源量可以配置，同一队列中的作业公平共享队列中所有资源

14. MapReduce 2.0 容错性

    1）MRAppMaster容错性
      一旦运行失败，由YARN的ResourceManager负责重新启动，最多重启次数可由用户设置，默认是2次。一旦超过最高重启次数，则作业运行失败。
    2）Map Task/Reduce
      Task Task周期性向MRAppMaster汇报心跳；一旦Task挂掉，则MRAppMaster将为之重新申请资源，并运行之。最多重新运行次数可由用户设置，默认4次。

15. mapreduce推测执行算法及原理

     发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。以空间换时间，但是这种方法需要占用更多的计算资源。在集群资源紧缺的情况下，应合理使用该机制，争取在多用少量资源的情况下，减少作业的计算时间。

16. MapReduce跑得慢的原因？

    1）计算机性能
    2）I/O 操作优化
      （1）数据倾斜
      （2）map和reduce数设置不合理
      （3）小文件过多，或大量不可分块超大文件
      （4）spill和merge次数过多

17. MapReduce优化方法

    1）数据输入
      （1）合并小文件：在执行mr任务前将小文件进行合并，大量的小文件会产生大量的map任务，增大map任务装载次数，而任务的装载比较耗时，从而导致mr运行较慢。
      （2）采用ConbinFileInputFormat来作为输入，解决输入端大量小文件场景。
    2）map阶段
      （1）减少spill次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发spill的内存上限，减少spill次数，从而减少磁盘 IO。
      （2）减少merge次数：通过调整io.sort.factor参数，增大merge的文件数目，减少merge的次数，从而缩短mr处理时间。
      （3）在 map 之后先进行combine处理，减少I/O。
    3）reduce阶段
      （1）合理设置map和reduce数：两个都不能设置太少，也不能设置太多。太少，会导致task等待，延长处理时间；太多，会导致 map、reduce任务间竞争资源，造成处理超时等错误。
      （2）设置map、reduce共存：调整slowstart.completedmaps参数，使map运行到一定程度后，reduce也开始运行，减少reduce的等待时间。
      （3）规避使用reduce，因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。
      （4）合理设置reduce端的buffer
    4）IO传输
      （1）采用数据压缩的方式，减少网络IO的的时间。安装Snappy和LZOP压缩编码器。
      （2）使用SequenceFile二进制文件
    5）数据倾斜问题
      （1）自定义分区
      （2）Combine。使用Combine可以大量地减小数据频率倾斜和数据大小倾斜。在可能的情况下，combine的目的就是聚合并精简数据。
    
18. HDFS小文件优化方法

    1）弊端：hive中小文件会增加map数量，资源占用多。hdfs中，小文件过多会大量占用namenode空间，增加寻址时间
    2）解决的方式：
      （1）Hadoop Archive：是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时。
      （2）Sequence file：sequence file由一系列的二进制key/value组成，如果为key小文件名，value为文件内容，则可以将大批小文件合并成一个大文件。
      （3）CombineFileInputFormat：CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split，另外，它会考虑数据的存储位置。

19. FileInputFormat切片机制

    waitForCompletion()提交任务
    connect 创建连接，在这之中判断是yarn还是远程
    submitJobInternam提交job
    创建任务配置存放的路径
    获取jobid
    拷贝jar包到集群（本地不需要）
    计算切片，生成切片规划文件
    向存放路径写job.xml 和 切片文件
    提交job

20. 在一个运行的Hadoop 任务中，什么是InputSplit？

    遍历目录，获取第一个文件，计算切片大小
    开始切，每次切完，判断剩下部分是否大于块的1.1倍，不大于就直接把剩下的划分为一块
    写入切片规划文件中，只记录起始位置，长度等
    提交到yarn上

21. MapTask和ReduceTask工作机制

    MapTask工作机制
        （1）Read阶段：Map Task通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。
        （2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。
        （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。
        （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。
        （5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。

    ReduceTask工作机制
        （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。
        （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。
        （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。 由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。
        （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。

22. 描述mapReduce有几种排序及排序发生的阶段

    部分排序，map端，保证每个文件内部有序
    全排序，一般只有一个reduce
    辅助排序，到达reducer之前按键对记录排序
    二次排序，判断条件为两个即为二次排序

23. 描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段

    分区，排序，溢写，拷贝到对应reduce机器上，增加combiner，压缩溢写的文件。

24. MapReduce 出现单点负载多大，怎么负载平衡？

    通过Partitioner实现

25. MapReduce 怎么实现 TopN

    定义辅助排序，对结果最大值排序，在reduce输出时，控制只输出前n个数。就达到了topn输出的目的。

26. Hadoop的缓存机制（Distributedcache）

    Distributedcache 将文件拷贝到hdfs中，jobClient 会通过 Distributedcache 创建符号链接， 

27. 如何使用mapReduce实现两个表的join?（Hive的两张表关联，使用MapReduce怎么实现？）

    如果是大表 join 大表：map函数读取key/value对时，将join on 的字段作为key，并且每一条数据打上flag，0为表A，1为表B
    如果是小表 join 大表：直接在map端将小表缓存，在map端与大表 join

28. Hive表关联查询，如何解决数据倾斜的问题？

    倾斜原因：map输出数据按key Hash的分配到reduce中，由于key分布不均匀、业务数据本身的特、建表时考虑不周、等原因造成的reduce 上的数据量差异过大。对于key为空产生的数据倾斜，可以对其赋予一个随机值
    参数调节：
    hive.map.aggr = true
    hive.groupby.skewindata=true
    有数据倾斜的时候进行负载均衡，当选项设定位true,生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果。第二个MR Job再根据预处理的数据结果按照Group By Key 分布到 Reduce 中，最后完成最终的聚合操作。
    SQL 语句调节
    选用join key分布最均匀的表作为驱动表
    使用map join让小的维度表先进内存。在map端完成reduce。
    count distinct大量相同特殊值

29. Hive的HSQL转换为MapReduce的过程？

     HiveSQL ->AST(抽象语法树) -> QB(查询块) ->OperatorTree（操作树）->优化后的操作树->mapreduce任务树->优化后的mapreduce任务树

     HiveSql 被 SQL parser 解析为 AST；hive 遍历 AST，抽象出 QB（为了更好地描述，转化HQL语句）；之后将QB转化为操作树，操作树会进行逻辑优化；之后通过特定引擎（mr，spark，tez）转化为任务树，任务树会进行物理优化，最后提交任务

30. Hive底层与数据库交互原理

    目前Hive将元数据存储在RDBMS中，比如存储在MySQL、Derby中。元数据信息包括：存在的表、表的列、权限和更多的其他信息

31. 请说明hive中 Sort By，Order By，Cluster By，Distrbute By各代表什么意思？

    order by：会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序）。只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。
    sort by：不是全局排序，其在数据进入reducer前完成排序。
    distribute by：按照指定的字段对数据进行划分输出到不同的reduce中。
    cluster by：除了具有 distribute by 的功能外还兼具 sort by 的功能。

32. 写出hive中split、coalesce及collect_list函数的用法

    split("a,b,c",",") 字符串 -> 数组
    coalesce() 第一个不为空的值
    collect_list() -> 列出字段所有值

33. Hive内部表和外部表的区别？

    内部表，数据会移动到数据仓库指向路径，删除时元数据和数据都删除
    外部表，仅记录数据路径，删除时只删除元数据

34. Hive 中的压缩格式TextFile、SequenceFile、RCfile 、ORCfile各有什么区别？

    TextFile 行存储，不做压缩，磁盘开销大，数据解析开销大
    SequenceFile 行存储，其具有使用方便、可分割、可压缩的特点
    ORCFile 数据按行分块，每块按列存储 数据加载时性能消耗较大，但是具有较好的压缩比和查询响应

35. Group By

    （1）是否在Map端进行聚合，默认为True
      hive.map.aggr = true
    （2）在Map端进行聚合操作的条目数目
      hive.groupby.mapaggr.checkinterval = 100000
    （3）有数据倾斜的时候进行负载均衡（默认是false）
      hive.groupby.skewindata = true（见28点）

36. 请简述Zookeeper的选举机制

    首次启动：
        （1）服务器1启动，此时只有它一台服务器启动了，投自己一票，它发出去的报没有任何响应，由于没有达到超过半数以上的服务器都同意选举它，所以它的选举状态一直是LOOKING状态。
        （2）服务器2启动，它与最开始启动的服务器1进行通信，都投自己一票，互相交换自己的选举结果，发现服务器2id大，服务器2胜出，超过一半，所以服务器1还是继续保持Follow状态，服务器2保持Leading
        （3）服务器3启动，发起投票，互相交换自己的选举结果，发现服务器2为leader，少数服从多数，投服务器2，自己变为Follow状态
    leader宕机：
        （1）epoch大胜出，相等比较zxid，大的胜出，最后比较服务器id

37. 海量日志数据，提取出某日访问百度次数最多的那个IP

    首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。

38. 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。

    第一步、先对这批海量数据预处理，在O（N）的时间内用Hash表完成排序；然后，第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即，借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比所以，我们最终的时间复杂度是：O（N） + N'*O（logK），（N为1000万，N’为300万）

39. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

    顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。
    如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。

40. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

    方案1：顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件（记为）。
    对这10个文件进行归并排序（内排序与外排序相结合）。
    方案2：一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。
    方案3：与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。

41. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

    方案1：可以估计每个文件的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。
    遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。
    遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0 vs b0,a1 vs b1,...,a999 vs b999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
    求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。
    方案2：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。

42. 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

    方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。
    方案2：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。

43. 腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

    方案1：申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。
    方案2：这个问题在《编程珠玑》里有很好的描述，大家可以参考下面的思路，探讨一下：又因为2^32为40亿多，所以给定一个数可能在，也可能不在其中；这里我们把40亿个数中的每一个用32位的二进制来表示假设这40亿个数开始放在一个文件中。
    然后将这40亿个数分成两类: 1.最高位为0 2.最高位为1 并将这两类分别写入到两个文件中，其中一个文件中数的个数<=20亿，而另一个>=20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找。再然后把这个文件为又分成两类: 1.次最高位为0 2.次最高位为1
    并将这两类分别写入到两个文件中，其中一个文件中数的个数<=10亿，而另一个>=10亿（这相当于折半了）；与要查找的数的次最高位比较并接着进入相应的文件再查找。以此类推，就可以找到了,而且时间复杂度为O(logn)，方案2完。

44. 怎么在海量数据中找出重复次数最多的一个？

    方案1：先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求（具体参考前面的题）。

45. 上千万或上亿数据（有重复），统计其中出现次数最多的钱N个数据。

    方案1：上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。然后就是取出前N个出现次数最多的数据了，可以用第2题提到的堆机制完成。

46. 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。

    先hash%1000 生成 1000个文件，每个文件统计词频，之后1000个文件归并，或进堆取前10个。

47. MySQL存储引擎MyISAM与InnoDB区别

    常用的存储引擎有以下：
    Innodb引擎：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。，事务等快。B+树索引，Innodb 是索引组织表。支持哈希索引，行级锁
    MyIASM引擎(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。MyISAM可被压缩，存储空间较小，查询快。B+树索引，myisam 是堆表，表级锁
    MEMORY引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。

48. 索引类型

    主键索引、唯一索引、普通索引、全文索引、Hash索引，B+树索引等

49. B树和B+树的区别

    在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。
    B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。
    使用B树的好处
    B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。
    使用B+树的好处
    由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。而B树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间

50. 数据库为什么使用B+树而不是B树

    B树只适合随机检索，而B+树同时支持随机检索和顺序检索；
    B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；
    B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。
    B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。
    增删文件（节点）时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。

51. 关系性数据库需要遵循ACID规则

    原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
    一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
    隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
    持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

52. 什么是脏读？幻读？不可重复读？

    脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。
    不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。
    幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。

53. 什么是事务的隔离级别？MySQL的默认隔离级别是什么？

    为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。

54. 死锁 必要条件

    互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
    占有和等待：已经得到了某个资源的进程可以再请求新的资源。
    不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
    环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

55. TCP 的三次握手

    假设 A 为客户端，B 为服务器端。
    首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
    A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
    B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
    A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
    B 收到 A 的确认后，连接建立。

56. 三次握手的原因

    第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。
    客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

57. TCP 的四次挥手

    A 发送连接释放报文，FIN=1。
    B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
    当 B 不再需要连接时，发送连接释放报文，FIN=1。
    A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
    B 收到 A 的确认后释放连接。

58. 四次挥手的原因

    客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

59. 范式

    第一范式 (1NF)属性不可分。
    第二范式 (2NF)每个非主属性完全函数依赖于键码。
    第三范式 (3NF)非主属性不传递函数依赖于键码。

60. hive 开窗函数

    rank(),dense_rank(),lag(),lead(),first_value(),last_value()

61. 如果一个datanode出现宕机，恢复流程是什么样的

62. 描述一下NameNode对元数据的管理

63. NameNode对元数据的管理机制是什么

64. 详细描述一下Yarn的调度流程

65. Mapreduce的map数量和reduce数量是由什么决定的

66. 你对MapReduce做过什么优化

    取消 虚拟内存检查，增加虚拟cpu数

67. DFS的系统架构是如何保证数据安全的

68. Hadoop的job和Task之间的区别是什么

69. Hadoop高可用HA模式如何配置？工作原理是什么？

70. 安装过集群吗？大概需要哪几步骤？

71. fsimage和edit的区别

72. 说出一些hadoop的常用shell命令

73. 谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化

74. 描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段

    增大环形缓冲区的阈值，使用combine进行预聚合，使用压缩

75. 描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？

76. MapReduce 怎么实现 TopN？写出关键代码

77. 文件大小设置，增大有什么影响？

78. 为什么会产生 yarn,它解决了什么问题，有什么优势？

79. spark oom处理方法 

80. g1和cms的区别 

81. Kafka ISR 机制 

82. String、StringBuffer和 StringBuilder的区别 

83. HashMap、ConcurrentMap和 Hashtable 区别 

84. 多线程的实现方法

85. java的内存溢出和内存泄漏

86. Java：面向对象、容器、多线程、单例 

87. sql 去重方法(group by 、distinct、窗口函数) 

88. Kafka 的ack 

89. HashMap、ConcurrentMap和 Hashtable 区别 

90. Time_wait状态？当server处理完client的请求后立刻closesocket此时会出现time_wait状态

91. Java 并发原理 

92. Hadoop active namenode 脑裂问题

93. Hive分析和窗口函数

94. 手写一个线程安全的单例 

95. Java 类加载过程

    加载 -> 验证 -> 准备 -> 初始化 -> 

96. 简述 HBase 的读写过程 

97. zookeeper 是如何保证数据一致性的 

98. 维度模型

